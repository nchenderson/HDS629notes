<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 1 Mixed Models for Longitudinal Data Analysis | Notes for Case Studies in Health Big Data</title>
  <meta name="description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 1 Mixed Models for Longitudinal Data Analysis | Notes for Case Studies in Health Big Data" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://nchenderson.github.io/HDS629notes/" />
  
  <meta property="og:description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  <meta name="github-repo" content="nchenderson/HDS629notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 Mixed Models for Longitudinal Data Analysis | Notes for Case Studies in Health Big Data" />
  
  <meta name="twitter:description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  

<meta name="author" content="Nicholas Henderson" />


<meta name="date" content="2021-01-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biostat 629</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>1</b> Mixed Models for Longitudinal Data Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="mixed-models.html"><a href="mixed-models.html#sec:methods-overview"><i class="fa fa-check"></i><b>1.1</b> Methods for Analyzing Longitudinal Data</a></li>
<li class="chapter" data-level="1.2" data-path="mixed-models.html"><a href="mixed-models.html#mixed-models-for-continuous-outcomes"><i class="fa fa-check"></i><b>1.2</b> Mixed Models for Continuous Outcomes</a></li>
<li class="chapter" data-level="1.3" data-path="mixed-models.html"><a href="mixed-models.html#advantages-of-using-random-effects"><i class="fa fa-check"></i><b>1.3</b> Advantages of using random effects</a><ul>
<li class="chapter" data-level="1.3.1" data-path="mixed-models.html"><a href="mixed-models.html#within-subject-correlation"><i class="fa fa-check"></i><b>1.3.1</b> Within-subject correlation</a></li>
<li class="chapter" data-level="1.3.2" data-path="mixed-models.html"><a href="mixed-models.html#inference-about-heterogeneity---variance-of-random-effects"><i class="fa fa-check"></i><b>1.3.2</b> Inference about Heterogeneity - Variance of Random Effects</a></li>
<li class="chapter" data-level="1.3.3" data-path="mixed-models.html"><a href="mixed-models.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>1.3.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="mixed-models.html"><a href="mixed-models.html#generalized-linear-mixed-models-glmms"><i class="fa fa-check"></i><b>1.4</b> Generalized linear mixed models (GLMMs)</a><ul>
<li class="chapter" data-level="1.4.1" data-path="mixed-models.html"><a href="mixed-models.html#glmms-with-binary-outcomes"><i class="fa fa-check"></i><b>1.4.1</b> GLMMs with Binary Outcomes</a></li>
<li class="chapter" data-level="1.4.2" data-path="mixed-models.html"><a href="mixed-models.html#glmms-with-count-outcomes"><i class="fa fa-check"></i><b>1.4.2</b> GLMMs with Count Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="mixed-models.html"><a href="mixed-models.html#fitting-linear-mixed-models-lmms-and-generalized-linear-mixed-models-glmms-in-r"><i class="fa fa-check"></i><b>1.5</b> Fitting Linear Mixed Models (LMMs) and Generalized Linear Mixed models (GLMMs) in <strong>R</strong></a><ul>
<li class="chapter" data-level="1.5.1" data-path="mixed-models.html"><a href="mixed-models.html#fitting-lmms-with-the-sleepstudy-data"><i class="fa fa-check"></i><b>1.5.1</b> Fitting LMMs with the sleepstudy data</a></li>
<li class="chapter" data-level="1.5.2" data-path="mixed-models.html"><a href="mixed-models.html#fitting-binary-glmms-using-the-ohio-data"><i class="fa fa-check"></i><b>1.5.2</b> Fitting Binary GLMMs using the Ohio data</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for Case Studies in Health Big Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mixed-models" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Mixed Models for Longitudinal Data Analysis</h1>
<hr />
<div id="sec:methods-overview" class="section level2">
<h2><span class="header-section-number">1.1</span> Methods for Analyzing Longitudinal Data</h2>
<ul>
<li><strong>Longitudinal data</strong> refers to data that:
<ul>
<li><p>Has multiple individuals/subjects.</p></li>
<li><p>Each individual has multiple observations that were taken across time.</p></li>
</ul></li>
<li>We will denote the outcomes of interest with <span class="math inline">\(Y_{ij}\)</span>.
<ul>
<li><p><span class="math inline">\(Y_{ij}\)</span> - outcome for individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(t_{ij}\)</span>.</p></li>
<li><p>The <span class="math inline">\(i^{th}\)</span> individual has <span class="math inline">\(n_{i}\)</span> observations: <span class="math inline">\(Y_{i1}, \ldots, Y_{in_{i}}\)</span>.</p></li>
<li><p>There will be <span class="math inline">\(m\)</span> individuals in the study (so <span class="math inline">\(1 \leq j \leq m\)</span>).</p></li>
</ul></li>
</ul>
<hr />
<p><img src="01-MixedModels_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<ul>
<li><p>The above figure shows an example of outcomes from a longitudinal study (the <strong>sleepstudy</strong> data in the <strong>lme4</strong> package).</p></li>
<li><p>In the <strong>sleepstudy</strong> data:</p>
<ul>
<li><p>The time points of observation <span class="math inline">\(t_{ij}\)</span> are the same for each individual <span class="math inline">\(i\)</span>. So, we can say <span class="math inline">\(t_{ij} = t_{j}\)</span> for all <span class="math inline">\(i\)</span>.</p></li>
<li><p>The outcome <span class="math inline">\(Y_{ij}\)</span> is the <strong>reaction time</strong> for the <span class="math inline">\(i^{th}\)</span> individual at time point <span class="math inline">\(t_{j}\)</span>.</p></li>
<li><p>The 10 time points are <span class="math inline">\((t_{1}, \ldots, t_{10}) = (0, 1, \ldots, 9)\)</span>.</p></li>
</ul></li>
</ul>
<hr />
<ul>
<li>Most of the well-known regression-based methods for analyzing longitudinal
data can be classified (see <span class="citation">Diggle et al. (<a href="#ref-diggle2013">2013</a>)</span>) into one of the three following
categories:
<ul>
<li><strong>Random effects/mixed models</strong>,</li>
<li><strong>Marginal models</strong>,</li>
<li><strong>Transition models</strong></li>
</ul></li>
<li><strong>Random effects/Mixed Models</strong>
<ul>
<li><p>“Random effects” are added to the regression model describing
the outcomes for each individual.</p></li>
<li><p>These “random regression coefficients” are viewed as a sample from some distribution.</p></li>
</ul></li>
<li><strong>Marginal models</strong>
<ul>
<li><p>Regression coefficients have a “population average” interpretation.</p></li>
<li><p>Only mean of <span class="math inline">\(Y_{ij}\)</span> and correlation structure of <span class="math inline">\((Y_{i1}, \ldots, Y_{in_{i}})\)</span> are modeled.</p></li>
<li><p>Generalized estimating equations (GEEs) are often used for estimating model parameters.</p></li>
</ul></li>
<li><strong>Transition models</strong>
<ul>
<li>Uses a probability model for the distribution of <span class="math inline">\(Y_{ij}\)</span> given the value of the outcome
at the previous time point <span class="math inline">\(Y_{ij-1}\)</span>.</li>
</ul></li>
</ul>
</div>
<div id="mixed-models-for-continuous-outcomes" class="section level2">
<h2><span class="header-section-number">1.2</span> Mixed Models for Continuous Outcomes</h2>
<ul>
<li><p>If each <span class="math inline">\(Y_{ij}\)</span> is a <strong>continuous outcome</strong> and we were to
build a regression model without any random effects, we might assume something like:
<span class="math display" id="eq:fixed-reg-model">\[\begin{equation}
Y_{ij} = \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + e_{ij}
\tag{1.1}
\end{equation}\]</span></p></li>
<li><p><span class="math inline">\(\mathbf{x}_{ij} = (x_{i1}, \ldots, x_{ip})\)</span> is the vector
of covariates for individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(j\)</span>.</p></li>
<li>The vector <span class="math inline">\(\mathbf{x}_{ij}\)</span> could contain individual information such as smoking status or age.
<ul>
<li><span class="math inline">\(\mathbf{x}_{ij}\)</span> could also contain some of the actual time points: <span class="math inline">\(t_{ij}, t_{ij-1}, ...\)</span>
or transformations of these time points.</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>The regression model <a href="mixed-models.html#eq:fixed-reg-model">(1.1)</a> assumes the same
mean function <span class="math inline">\(\beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta}\)</span> holds for all individuals in the study.</p></li>
<li>It is often reasonable to assume that the regression coefficients across vary across individuals.
<ul>
<li>This can often better account for heterogeneity across individuals.</li>
</ul></li>
<li>The figure below shows 3 different regression lines from the <strong>sleepstudy</strong> data.
<ul>
<li>Each regression line was estimated using only data from one individual.</li>
</ul></li>
</ul>
<div class="figure"><span id="fig:unnamed-chunk-2"></span>
<img src="01-MixedModels_files/figure-html/unnamed-chunk-2-1.png" alt="Separately estimated regression lines for 3 subjects in the sleepstudy data." width="672" />
<p class="caption">
Figure 1.1: Separately estimated regression lines for 3 subjects in the sleepstudy data.
</p>
</div>
<hr />
<ul>
<li><p>Figure 1.1 suggests there is some heterogeneity in the <strong>relationship</strong>
between <strong>study day</strong> and <strong>response time</strong> across individuals.</p></li>
<li><p>The response time of <strong>Subject 309</strong> changes very little over time.</p></li>
<li><p>For <strong>Subject 308</strong>, there is a more clear positive association between
response time and day of study.</p></li>
</ul>
<hr />
<ul>
<li>For the <strong>sleepstudy</strong> data, a linear regression for <strong>reaction time</strong> vs. <strong>study day</strong>
which assumes that
<ol style="list-style-type: decimal">
<li>Expected response time is a linear function of study day,</li>
<li>All individuals have the same regression coefficients,</li>
</ol></li>
</ul>
<p>would have the form:
<span class="math display">\[\begin{equation}
Y_{ij} = \beta_{0} + \beta_{1} t_{j} + e_{ij}
\end{equation}\]</span></p>
<ul>
<li><p>If we allowed each individual to have his/her <strong>own intercept and slope</strong>, we
could instead consider the following model
<span class="math display" id="eq:mixed-sleep">\[\begin{equation}
Y_{ij} = \beta_{0} + \beta_{1} t_{j} + u_{i0} + u_{i1}t_{j} + e_{ij}
\tag{1.2}
\end{equation}\]</span></p></li>
<li><span class="math inline">\(\beta_{0} + u_{i0}\)</span> - intercept for individual <span class="math inline">\(i\)</span>.</li>
<li><p><span class="math inline">\(\beta_{1} + u_{i1}\)</span> - intercept for individual <span class="math inline">\(i\)</span>.</p></li>
</ul>
<hr />
<ul>
<li><p>If we assume <span class="math inline">\((u_{i0}, u_{i1})\)</span> are sampled from some distribution, <span class="math inline">\(u_{i0}\)</span> and
<span class="math inline">\(u_{i1}\)</span> are referred to as <strong>random effects</strong>.</p></li>
<li><p>Typically, it is assumed that <span class="math inline">\((u_{i0}, u_{i1})\)</span> are sampled from a multivariate normal distribution
with mean zero:
<span class="math display">\[\begin{equation}
(u_{i0}, u_{i1}) \sim \textrm{Normal}( \mathbf{0}, \boldsymbol{\Sigma}_{\tau} )
\end{equation}\]</span></p></li>
<li><p>Model <a href="mixed-models.html#eq:mixed-sleep">(1.2)</a> is called a <strong>mixed model</strong> because
it contains both <strong>fixed effects</strong> <span class="math inline">\((\beta_{0}, \beta_{1})\)</span>
and <strong>random effects</strong> <span class="math inline">\((u_{i0}, u_{i1})\)</span>.</p></li>
</ul>
<hr />
<ul>
<li>More generally, a <strong>linear mixed model</strong> (LMM) for longitudinal data will have the form:
<span class="math display" id="eq:lmm-generalform">\[\begin{equation}
Y_{ij} = \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}\mathbf{u}_{i} + e_{ij}
\tag{1.3}
\end{equation}\]</span>
<ul>
<li><span class="math inline">\(\boldsymbol{\beta}\)</span> - vector of fixed effects</li>
<li><span class="math inline">\(\mathbf{u}_{i}\)</span> - vector of random effects</li>
</ul></li>
<li>If we stack the responses into a long vector <span class="math inline">\(\mathbf{Y}\)</span> and random effects into a long vector <span class="math inline">\(\mathbf{u}\)</span>
<ul>
<li><span class="math inline">\(\mathbf{Y} = (Y_{11}, Y_{12}, ...., Y_{mn_{m}})\)</span> - this vector has length <span class="math inline">\(\sum_{k=1}^{m} n_{k}\)</span></li>
<li><span class="math inline">\(\mathbf{u} = (u_{10}, u_{11}, ...., u_{mq})\)</span> - this vector has length <span class="math inline">\(m \times (q + 1)\)</span>.</li>
</ul></li>
<li>Then, we can write the general form <a href="mixed-models.html#eq:lmm-generalform">(1.3)</a> of the LMM as
<span class="math display">\[\begin{equation}
\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} + \mathbf{Z}\mathbf{u} + \mathbf{e}
\end{equation}\]</span>
<ul>
<li><span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(\mathbf{X}\)</span> is <span class="math inline">\((1, \mathbf{x}_{ij}^{T})\)</span>.</li>
<li><span class="math inline">\(i^{th}\)</span> row of <span class="math inline">\(\mathbf{Z}\)</span> is <span class="math inline">\(\mathbf{z}_{ij}^{T}\)</span>.</li>
</ul></li>
<li>Constructing an LMM can be thought of as choosing the desired “<span class="math inline">\(\mathbf{X}\)</span>” and “<span class="math inline">\(\mathbf{Z}\)</span>” matrices.</li>
</ul>
</div>
<div id="advantages-of-using-random-effects" class="section level2">
<h2><span class="header-section-number">1.3</span> Advantages of using random effects</h2>
<div id="within-subject-correlation" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Within-subject correlation</h3>
<ul>
<li>Using an LMM automatically accounts for the “<strong>within-subject</strong>” correlation.
<ul>
<li>That is, the correlation between two observations from the same individual.</li>
</ul></li>
<li><p>This correlation arises because observations on the same individual “share” <strong>common</strong> random effects.</p></li>
<li><p>The correlation between the <span class="math inline">\(j^{th}\)</span> and <span class="math inline">\(k^{th}\)</span> observation from individual <span class="math inline">\(i\)</span> is
<span class="math display">\[\begin{equation}
\textrm{Corr}(Y_{ij}, Y_{ik}) = \frac{ \mathbf{z}_{ij}^{T}\boldsymbol{\Sigma}_{\tau}\mathbf{z}_{ik}  }{ \sqrt{\sigma^{2} + \mathbf{z}_{ij}^{T}\boldsymbol{\Sigma}_{\tau}\mathbf{z}_{ij}}\sqrt{\sigma^{2} + \mathbf{z}_{ik}^{T}\boldsymbol{\Sigma}_{\tau}\mathbf{z}_{ik}}}
\end{equation}\]</span></p></li>
</ul>
<hr />
<ul>
<li>When using <strong>only a random intercept</strong>, the correlation between <span class="math inline">\(Y_{ij}\)</span> and <span class="math inline">\(Y_{ik}\)</span> is
<span class="math display">\[\begin{equation}
\textrm{Corr}(Y_{ij}, Y_{ik}) = \frac{ \sigma_{u}^{2}  }{ \sigma^{2} + \sigma_{u}^{2} }
\end{equation}\]</span>
<ul>
<li>In this case, <span class="math inline">\(\mathbf{z}_{ij} = 1\)</span> and <span class="math inline">\(u_{i} \sim \textrm{Normal}(0, \sigma_{u}^{2})\)</span></li>
<li><span class="math inline">\(\sigma^{2}\)</span> is the variance of the residual term <span class="math inline">\(e_{ij}\)</span></li>
</ul></li>
<li>For longitudinal data, one criticism of the random intercept model is that the within-subject
correlation <strong>does not vary</strong> across time.</li>
</ul>
</div>
<div id="inference-about-heterogeneity---variance-of-random-effects" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Inference about Heterogeneity - Variance of Random Effects</h3>
<ul>
<li><p>One of the goals of the data analysis may be to characterize
the <strong>heterogeneity</strong> in the relationship between the outcome
and some of the covariates across individuals.</p></li>
<li><p>Looking at the estimates of the variance of the random effects
is one way of addressing this goal.</p></li>
<li><p>An estimate of <span class="math inline">\(\textrm{Var}( u_{ih} )\)</span> “substantially greater than zero”
is an indication that there is variability in the covariate corresponding to <span class="math inline">\(u_{ih}\)</span>
across individuals.</p></li>
</ul>
<hr />
<ul>
<li><p>For example, with the random intercept and slope model for the <strong>sleepstudy</strong> data
<span class="math display">\[\begin{equation}
Y_{ij} = \beta_{0} + \beta_{1}t_{j} + u_{i0} + u_{i1}t_{j} + e_{ij}
\end{equation}\]</span></p></li>
<li>If <span class="math inline">\(\textrm{Var}( u_{i1} )\)</span> is “large”, this implies that the response
to additional days of sleep deprivation <strong>varies considerably</strong> across individuals.
<ul>
<li><p>The response time of some individuals is not impacted much by additional days of little sleep.</p></li>
<li><p>Some individuals respond strongly to additional days of little sleep.</p></li>
</ul></li>
</ul>
<!--* When interpreting the estimated values of the random-effects variances, 
one thing you could report is the variation explained -->
</div>
<div id="best-linear-unbiased-prediction" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Best Linear Unbiased Prediction</h3>
<ul>
<li><p>You may want to estimate or <strong>“predict”</strong> the mean function/trajectory
of a given individual.</p></li>
<li><p>This means you want to estimate/predict the following quantity:
<span class="math display">\[\begin{equation}
\beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}\mathbf{u}_{i}
\end{equation}\]</span></p></li>
<li><p>The “Best Linear Unbiased Predictor” (BLUP) of this is
<span class="math display">\[\begin{equation}
\textrm{BLUP}_{ij} = \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}E(\mathbf{u}_{i}|Y_{i1}, \ldots, Y_{in_{i}})
\end{equation}\]</span></p></li>
</ul>
<hr />
<ul>
<li><p>I would think of the values of <span class="math inline">\(\textrm{BLUP}_{ij}\)</span> (for different values of <span class="math inline">\(j\)</span>) as an estimate of the “true trajectory” (i.e., the true mean) of the <span class="math inline">\(i^{th}\)</span> individual.</p></li>
<li><p>The observed longitudinal outcomes from individual <span class="math inline">\(i\)</span> are a “noisy estimate” of that individual’s true trajectory.</p></li>
<li>The BLUPs are more stable <strong>“shrinkage” estimates</strong> of the trajectory of individual <span class="math inline">\(i\)</span>.
<ul>
<li>These are called shrinkage estimates because <span class="math inline">\(\textrm{BLUP}_{ij}\)</span> often shrinks the estimate from data only from individual <span class="math inline">\(i\)</span> towards the “overall” estimate <span class="math inline">\(\mathbf{x}_{ij}^{T}\boldsymbol{\beta}\)</span>.</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>For example, if we had the intercept-only model <span class="math inline">\(Y_{ij} = \beta_{0} + u_{i} + e_{ij}\)</span>,
the value of <span class="math inline">\(\textrm{BLUP}_{ij}\)</span> is
<span class="math display">\[\begin{equation}
\textrm{BLUP}_{ij} = \frac{n_{i}\sigma_{u}^{2}}{\sigma^{2} + n_{i}\sigma_{u}^{2} }\bar{Y}_{i.} + \Big(1 -  \frac{n_{i}\sigma_{u}^{2}}{\sigma^{2} + n_{i}\sigma_{u}^{2} }\Big)\bar{Y}_{..}
\end{equation}\]</span></p></li>
<li><span class="math inline">\(\bar{Y}_{i.}\)</span> is the sample mean from individual-<span class="math inline">\(i\)</span> data
<ul>
<li>This would be the estimate of the intercept if we only looked at data from the <span class="math inline">\(i^{th}\)</span> individual.</li>
</ul></li>
<li><span class="math inline">\(\bar{Y}_{..}\)</span> - overall mean
<ul>
<li>This would be the estimate of the intercept if we ignored variation in intercepts across individuals.</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>You can also think of <span class="math inline">\(\textrm{BLUP}_{ij}\)</span> as a prediction of what the observed
trajectory for individual <span class="math inline">\(i\)</span> would be if that individual
were in a future study under the same conditions.</p></li>
<li><p>Say <span class="math inline">\(Y_{i1}&#39;, \ldots, Y_{in_{i}}&#39;\)</span> are the observations for individual <span class="math inline">\(i\)</span> in a future study.</p></li>
<li><p>The outcomes in the future study are determined by
<span class="math display">\[\begin{equation}
Y_{ij}&#39; = \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}\mathbf{u}_{i} + e_{ij}&#39;
\end{equation}\]</span></p></li>
<li><p>The expectation of <span class="math inline">\(Y_{ij}&#39;\)</span> given the observed data in our longitudinal study is
<span class="math display">\[\begin{eqnarray}
E(Y_{ij}&#39;|Y_{i1}, \ldots, Y_{in_{i}}) &amp;=&amp; \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}E(\mathbf{u}_{i}|Y_{i1}, \ldots, Y_{in_{i}})  \nonumber \\
&amp;=&amp; \textrm{BLUP}_{ij} \nonumber
\end{eqnarray}\]</span></p></li>
</ul>
</div>
</div>
<div id="generalized-linear-mixed-models-glmms" class="section level2">
<h2><span class="header-section-number">1.4</span> Generalized linear mixed models (GLMMs)</h2>
<ul>
<li><p>Generalized linear models (GLMs) are used to handle “non-continuous” data
that can’t be reasonably modeled with a Gaussian distribution.</p></li>
<li><p>The most common scenarios where you would use GLMs in practice
are <strong>binary</strong>, <strong>count</strong>, and <strong>multinomial</strong> outcomes.</p></li>
<li><p>With a generalized linear mixed model (GLMM), you assume that
a GLM holds conditional on the value of the random effects.</p></li>
</ul>
<div id="glmms-with-binary-outcomes" class="section level3">
<h3><span class="header-section-number">1.4.1</span> GLMMs with Binary Outcomes</h3>
<ul>
<li><p>Under the GLM framework, the usual approach for handling binary outcomes is <strong>logistic regression</strong>.</p></li>
<li>The assumptions underying logistic regression are:
<ul>
<li><p>The outcomes are <strong>independent</strong></p></li>
<li><p>Each outcome follows a <strong>Bernoulli</strong> distribution.</p></li>
<li><p>The <strong>log-odds parameter</strong> is assumed to be a linear combination of the covariates.</p></li>
</ul></li>
</ul>
<hr />
<ul>
<li>With the GLMM version of logistic regression, we will make almost the same assumptions as the regular GLM
version of logistic regression.
<ul>
<li>The main difference is that each assumption in the GLMM will be <strong>conditional</strong> on the values of the random effects.</li>
</ul></li>
<li>To be specific, for longitudinal binary outcomes <span class="math inline">\(Y_{ij}\)</span>,
the GLMM version of logistic regression assumes the following:
<ol style="list-style-type: decimal">
<li><p><strong>Conditional</strong> on the vector of random effects <span class="math inline">\(\mathbf{u}_{i}\)</span>
<span class="math display">\[\begin{equation}
Y_{i1}, \ldots, Y_{in_{i}}|\mathbf{u}_{i}  \textrm{ are independent }
\end{equation}\]</span></p></li>
<li><p><strong>Conditional</strong> on <span class="math inline">\(\mathbf{u}_{i}\)</span>, each <span class="math inline">\(Y_{ij}\)</span> has a Bernoulli distribution
<span class="math display">\[\begin{equation}
Y_{ij}|\mathbf{u}_{i} \sim \textrm{Bernoulli}\big\{ p_{ij}(\mathbf{u}_{i}) \big\}
\end{equation}\]</span>
so that <span class="math inline">\(p_{ij}( \mathbf{u}_{i} ) = P(Y_{ij} = 1| \mathbf{u}_{i})\)</span>.</p></li>
<li><p>The “<strong>conditional</strong>” log-odds term <span class="math inline">\(\log\{ p_{ij}(\mathbf{u}_{i})/[1 - p_{ij}(\mathbf{u}_{i})] \}\)</span>
is a linear combination of the covariates and the random effects vector <span class="math inline">\(\mathbf{u}_{i}\)</span>:
<span class="math display">\[\begin{equation}
\textrm{logit}\{ p_{ij}(\mathbf{u}_{i}) \} = \log\Big( \frac{ p_{ij}(\mathbf{u}_{i})}{ 1 - p_{ij}(\mathbf{u}_{i}) } \Big)
= \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}\mathbf{u}_{i}
\end{equation}\]</span></p></li>
<li><p>As with a linear mixed model, we assume that the random-effects vector <span class="math inline">\(\mathbf{u}_{i}\)</span> has a <strong>multivariate normal distribution</strong> with mean zero and covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}_{\tau}\)</span>
<span class="math display">\[\begin{equation}
 \mathbf{u}_{i} \sim \textrm{Normal}( \mathbf{0}, \boldsymbol{\Sigma}_{\tau})
  \end{equation}\]</span></p></li>
</ol></li>
</ul>
</div>
<div id="glmms-with-count-outcomes" class="section level3">
<h3><span class="header-section-number">1.4.2</span> GLMMs with Count Outcomes</h3>
<ul>
<li><p>For <strong>count</strong> outcomes, responses are typically assumed to follow a <strong>Poisson</strong> distribution and sometimes a <strong>negative binomial</strong> distribution - conditional on the values of the random effects model.</p></li>
<li><p>For the Poisson model, we assume <span class="math inline">\(Y_{ij}|\mathbf{u}_{i} \sim \textrm{Poisson}\{ \mu_{ij}( \mathbf{u}_{i} ) \}\)</span>,
<span class="math display">\[\begin{equation}
E(Y_{ij}| \mathbf{u}_{i}) = \mu_{ij}(\mathbf{u}_{i})  \qquad 
\textrm{Var}( Y_{ij}| \mathbf{u}_{i} ) = \mu_{ij}(\mathbf{u}_{i})
\end{equation}\]</span></p></li>
<li>One common problem with the Poisson distribution is <strong>overdispersion</strong>.
<ul>
<li><p>The variance of the Poisson equals the mean.</p></li>
<li><p>While the <strong>marginal</strong> variance will not equal the mean, requiring the
conditional means and variances to be equal could lead to a poor fit.</p></li>
</ul></li>
<li>For the <strong>negative binomial</strong> model, we assume<br />
<span class="math inline">\(Y_{ij}|\mathbf{u}_{i} \sim \textrm{NB}\{ \mu_{ij}( \mathbf{u}_{i}, \phi ) \}\)</span>,
<span class="math display">\[\begin{equation}
E(Y_{ij}| \mathbf{u}_{i}) = \mu_{ij}(\mathbf{u}_{i})  \qquad 
\textrm{Var}( Y_{ij}| \mathbf{u}_{i} ) = \mu_{ij}(\mathbf{u}_{i}) + \phi\mu_{ij}^{2}(\mathbf{u}_{i})
\end{equation}\]</span>
<ul>
<li><span class="math inline">\(\phi\)</span> is often referred to as the overdispersion parameter.</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>With a GLMM model for <strong>count data</strong>, it is typical to model the <strong>log</strong> of the conditional mean <span class="math inline">\(\mu_{ij}(\mathbf{u}_{i})\)</span> with a linear regression:
<span class="math display">\[\begin{equation}
\log\{ \mu_{ij}(\mathbf{u}_{i}) \} = \beta_{0} + \mathbf{x}_{ij}^{T}\boldsymbol{\beta} + \mathbf{z}_{ij}^{T}\mathbf{u}_{i}
\end{equation}\]</span></p></li>
<li><p>Again, for the Poisson GLMM, the usual assumption for the random effects is that
<span class="math display">\[\begin{equation}
      \mathbf{u}_{i} \sim \textrm{Normal}( \mathbf{0}, \boldsymbol{\Sigma}_{\tau})
\end{equation}\]</span></p></li>
</ul>
</div>
</div>
<div id="fitting-linear-mixed-models-lmms-and-generalized-linear-mixed-models-glmms-in-r" class="section level2">
<h2><span class="header-section-number">1.5</span> Fitting Linear Mixed Models (LMMs) and Generalized Linear Mixed models (GLMMs) in <strong>R</strong></h2>
<ul>
<li>The <strong>lme4</strong> package is probably the most general package
for fitting LMMs and GLMMs.</li>
</ul>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(lme4)</a></code></pre></div>
<div id="fitting-lmms-with-the-sleepstudy-data" class="section level3">
<h3><span class="header-section-number">1.5.1</span> Fitting LMMs with the sleepstudy data</h3>
<ul>
<li>To start off, let’s use the <strong>sleepstudy</strong> longitudinal data in <strong>lme4</strong>
and look at the data from the first two individuals in this data.</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="kw">data</span>(sleepstudy) </a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="kw">dim</span>(sleepstudy) <span class="co"># 18 individuals, each with 10 observations</span></a></code></pre></div>
<pre><code>## [1] 180   3</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">sleepstudy[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,] <span class="co"># Data from the subjects with ids: 308 and 309</span></a></code></pre></div>
<pre><code>##    Reaction Days Subject
## 1  249.5600    0     308
## 2  258.7047    1     308
## 3  250.8006    2     308
## 4  321.4398    3     308
## 5  356.8519    4     308
## 6  414.6901    5     308
## 7  382.2038    6     308
## 8  290.1486    7     308
## 9  430.5853    8     308
## 10 466.3535    9     308
## 11 222.7339    0     309
## 12 205.2658    1     309
## 13 202.9778    2     309
## 14 204.7070    3     309
## 15 207.7161    4     309
## 16 215.9618    5     309
## 17 213.6303    6     309
## 18 217.7272    7     309
## 19 224.2957    8     309
## 20 237.3142    9     309</code></pre>
<ul>
<li>The <strong>sleepstudy</strong> data is an example of longitudinal data stored in <strong>long format</strong>
(as opposed to “wide” format).
<ul>
<li>In <strong>long format</strong>, each row of the dataset corresponds to an observation from one individual at one time point.</li>
</ul></li>
</ul>
<hr />
<ul>
<li>The <strong>lmer</strong> function in <strong>lme4</strong> fits linear mixed models.
<ul>
<li>This has many of the same features as the <strong>lm</strong> function in <strong>R</strong>.</li>
</ul></li>
<li><p>To fit an LMM with <strong>lmer</strong>, the main thing to do is to specify
the “X” part of the model (i.e., the fixed effects) and the “Z” part of the
model (i.e., the random effects).</p></li>
<li><p>The “X” part of the model is done using
the exact same “formula notation” used in the <strong>lm</strong> function.</p></li>
<li><p>The “Z” part of the model is done using the following type of syntax:</p></li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1">(formula <span class="op">|</span><span class="st"> </span>group_var)</a></code></pre></div>
<ul>
<li><code>group_var</code> is the “grouping variable” used for the random effects
<ul>
<li>This would be the variable telling you which</li>
</ul></li>
</ul>
<div id="lmm-with-a-single-random-intercept-for-each-subject" class="section level4">
<h4><span class="header-section-number">1.5.1.1</span> LMM with a single, random intercept for each subject</h4>
<ul>
<li><p>Let’s fit an LMM where there is a fixed slope for time
and only a random intercept for each <code>Subject</code>
<span class="math display" id="eq:lmm-intercept-sleep">\[\begin{equation}
Y_{ij} = \beta_{0} + \beta_{1}t_{j} + u_{i} + e_{ij}
\tag{1.4}
\end{equation}\]</span></p></li>
<li>For the “X” part of this model, we use <code>Reaction ~ Days</code>.
<ul>
<li>This gives us a fixed intercept and a fixed slope for the <code>Days</code> variable.</li>
</ul></li>
<li>For the “Z” part of this model, we just add <code>(1|Subject)</code>.
<ul>
<li>This says that there is only a random intercept within the grouping variable <code>Subject</code>.</li>
</ul></li>
<li><p>Putting these two together, we can fit the LMM <a href="mixed-models.html#eq:lmm-intercept-sleep">(1.4)</a> using the following code:</p></li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">lmm.sleep.intercept &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">|</span>Subject), <span class="dt">data =</span> sleepstudy)</a></code></pre></div>
<hr />
<ul>
<li><p>You can always use the <code>model.matrix</code> method on
the fitted <code>lmer</code> object to check that the “X” and “Z” matrices
correspond to the model you want.</p></li>
<li><p>Let’s look at the first 5 rows of the “X” matrix from <code>lmm.sleep.intercept</code></p></li>
</ul>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">x.mat &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(lmm.sleep.intercept)</a>
<a class="sourceLine" id="cb8-2" data-line-number="2"><span class="co">## This design matrix should have an intercept column</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3"><span class="co">## and a column which stores the &quot;Days&quot; variable</span></a>
<a class="sourceLine" id="cb8-4" data-line-number="4">x.mat[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,]</a></code></pre></div>
<pre><code>##   (Intercept) Days
## 1           1    0
## 2           1    1
## 3           1    2
## 4           1    3
## 5           1    4</code></pre>
<ul>
<li>Let’s look at the first 20 rows of the “Z” matrix from <code>lmm.intercept</code></li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="co">## Use argument type = &quot;random&quot; to get random-effects design matrix</span></a>
<a class="sourceLine" id="cb10-2" data-line-number="2">z.mat &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(lmm.sleep.intercept, <span class="dt">type=</span><span class="st">&quot;random&quot;</span>)</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">z.mat[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,] <span class="co"># The . values in zmat correspond to zeros</span></a></code></pre></div>
<pre><code>## 20 x 18 sparse Matrix of class &quot;dgCMatrix&quot;</code></pre>
<pre><code>##    [[ suppressing 18 column names &#39;308&#39;, &#39;309&#39;, &#39;310&#39; ... ]]</code></pre>
<pre><code>##                                       
## 1  1 . . . . . . . . . . . . . . . . .
## 2  1 . . . . . . . . . . . . . . . . .
## 3  1 . . . . . . . . . . . . . . . . .
## 4  1 . . . . . . . . . . . . . . . . .
## 5  1 . . . . . . . . . . . . . . . . .
## 6  1 . . . . . . . . . . . . . . . . .
## 7  1 . . . . . . . . . . . . . . . . .
## 8  1 . . . . . . . . . . . . . . . . .
## 9  1 . . . . . . . . . . . . . . . . .
## 10 1 . . . . . . . . . . . . . . . . .
## 11 . 1 . . . . . . . . . . . . . . . .
## 12 . 1 . . . . . . . . . . . . . . . .
## 13 . 1 . . . . . . . . . . . . . . . .
## 14 . 1 . . . . . . . . . . . . . . . .
## 15 . 1 . . . . . . . . . . . . . . . .
## 16 . 1 . . . . . . . . . . . . . . . .
## 17 . 1 . . . . . . . . . . . . . . . .
## 18 . 1 . . . . . . . . . . . . . . . .
## 19 . 1 . . . . . . . . . . . . . . . .
## 20 . 1 . . . . . . . . . . . . . . . .</code></pre>
<ul>
<li><p>The <code>.</code> values in <code>z.mat</code> are just zeros.</p></li>
<li>Notice that each <code>Subject</code> has its own “intercept” column.
<ul>
<li>This what we want - each <code>Subject</code> has its own intercept.</li>
</ul></li>
</ul>
<hr />
<ul>
<li>Let’s look at the <strong>estimated parameters</strong> from the LMM
with random intercepts using <code>summary</code></li>
</ul>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">summary</span>(lmm.sleep.intercept)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (1 | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1786.5
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.2257 -0.5529  0.0109  0.5188  4.2506 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  Subject  (Intercept) 1378.2   37.12   
##  Residual              960.5   30.99   
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept) 251.4051     9.7467   25.79
## Days         10.4673     0.8042   13.02
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.371</code></pre>
<ul>
<li><p>The estimated fixed-effects intercept is <span class="math inline">\(\hat{\beta}_{0} = 251.4\)</span>,
and the estimated fixed-effects slope is <span class="math inline">\(\hat{\beta}_{1} = 10.5\)</span>.</p></li>
<li>The estimated variance of the random intercept is <span class="math inline">\(\hat{\tau}^{2} = 1378.2\)</span>
(standard deviation is <span class="math inline">\(\hat{\tau} = 37.1\)</span>).
<ul>
<li>i.e., it is estimated that <span class="math inline">\(u_{i} \sim \textrm{Normal}(0, 1378.2)\)</span>.</li>
</ul></li>
</ul>
</div>
<div id="lmm-with-both-a-random-intercept-and-slope-for-each-subject" class="section level4">
<h4><span class="header-section-number">1.5.1.2</span> LMM with both a random intercept and slope for each subject</h4>
<ul>
<li><p>Now, let’s fit an LMM where there is a fixed slope for time
and both a random intercept and slope for each <code>Subject</code>
<span class="math display" id="eq:lmm-slope-sleep">\[\begin{equation}
Y_{ij} = \beta_{0} + \beta_{1}t_{j} + u_{i0} + u_{i1}t_{j} + e_{ij}
\tag{1.5}
\end{equation}\]</span></p></li>
<li><p>This is done with <code>lmer</code> using the following code:</p></li>
</ul>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1">lmm.sleep.slope &lt;-<span class="st"> </span><span class="kw">lmer</span>(Reaction <span class="op">~</span><span class="st"> </span>Days <span class="op">+</span><span class="st"> </span>(Days<span class="op">|</span>Subject), <span class="dt">data =</span> sleepstudy)</a></code></pre></div>
<ul>
<li>Again, let’s check the “X” and “Z” matrices from
<code>lmm.sleep.slope</code> to double-check that everything makes sense</li>
</ul>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">x.mat2 &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(lmm.sleep.slope)</a>
<a class="sourceLine" id="cb17-2" data-line-number="2"><span class="co">## This design matrix should be the same as that from lmm.sleep.intercept</span></a>
<a class="sourceLine" id="cb17-3" data-line-number="3">x.mat2[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,]</a></code></pre></div>
<pre><code>##   (Intercept) Days
## 1           1    0
## 2           1    1
## 3           1    2
## 4           1    3
## 5           1    4</code></pre>
<ul>
<li>First 20 rows of the “Z” matrix from <code>lmm.sleep.slope</code>:</li>
</ul>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co">## Use argument type = &quot;random&quot; to get random-effects design matrix</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">z.mat2 &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(lmm.sleep.slope, <span class="dt">type=</span><span class="st">&quot;random&quot;</span>)</a>
<a class="sourceLine" id="cb19-3" data-line-number="3">z.mat2[<span class="dv">1</span><span class="op">:</span><span class="dv">20</span>,] <span class="co"># The . values in zmat2 correspond to zeros</span></a></code></pre></div>
<pre><code>## 20 x 36 sparse Matrix of class &quot;dgCMatrix&quot;</code></pre>
<pre><code>##    [[ suppressing 36 column names &#39;308&#39;, &#39;308&#39;, &#39;309&#39; ... ]]</code></pre>
<pre><code>##                                                                           
## 1  1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 2  1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 3  1 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 4  1 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 5  1 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 6  1 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 7  1 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 8  1 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 9  1 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 10 1 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 11 . . 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 12 . . 1 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 13 . . 1 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 14 . . 1 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 15 . . 1 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 16 . . 1 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 17 . . 1 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 18 . . 1 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 19 . . 1 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
## 20 . . 1 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</code></pre>
<ul>
<li>Note that the two columns for each <code>Subject</code> in <code>z.mat2</code>
are of the form <span class="math inline">\((1, t_{j})\)</span>, which is what we want.</li>
</ul>
<hr />
<ul>
<li>Let’s look at the <strong>estimated parameters</strong> from <code>lmm.sleep.slope</code></li>
</ul>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">summary</span>(lmm.sleep.slope)</a></code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: Reaction ~ Days + (Days | Subject)
##    Data: sleepstudy
## 
## REML criterion at convergence: 1743.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -3.9536 -0.4634  0.0231  0.4634  5.1793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  Subject  (Intercept) 612.10   24.741       
##           Days         35.07    5.922   0.07
##  Residual             654.94   25.592       
## Number of obs: 180, groups:  Subject, 18
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  251.405      6.825  36.838
## Days          10.467      1.546   6.771
## 
## Correlation of Fixed Effects:
##      (Intr)
## Days -0.138</code></pre>
<ul>
<li><p>The estimated fixed-effects coefficients are <span class="math inline">\(\hat{\beta}_{0} = 251.4\)</span>,
and <span class="math inline">\(\hat{\beta}_{1} = 10.5\)</span> respectively.</p></li>
<li>The estimated standard deviation and correlation of the random effects are
<ul>
<li><p>Estimated standard deviation of <span class="math inline">\(u_{i0}\)</span> is <span class="math inline">\(24.7\)</span>.</p></li>
<li><p>Estimated standard deviation of <span class="math inline">\(u_{i1}\)</span> is <span class="math inline">\(5.9\)</span>.</p></li>
<li><p>Estimated correlation between <span class="math inline">\(u_{i0}\)</span> and <span class="math inline">\(u_{i1}\)</span> is <span class="math inline">\(0.07\)</span>.</p></li>
</ul></li>
</ul>
<hr />
<ul>
<li>Rather than always printing out the entire summary, you can directly extract the estimates of the fixed effects with</li>
</ul>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1"><span class="kw">coef</span>( <span class="kw">summary</span>(lmm.sleep.slope) )</a></code></pre></div>
<pre><code>##              Estimate Std. Error   t value
## (Intercept) 251.40510   6.824597 36.838090
## Days         10.46729   1.545790  6.771481</code></pre>
<ul>
<li>To directly extract the estimates of the variance (or standard deviation) of the
random effects, you can use:</li>
</ul>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="kw">VarCorr</span>( lmm.sleep.slope )</a></code></pre></div>
<pre><code>##  Groups   Name        Std.Dev. Corr 
##  Subject  (Intercept) 24.7407       
##           Days         5.9221  0.066
##  Residual             25.5918</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="co">## using as.numeric( VarCorr( lmm.sleep.slope ) ) will give</span></a>
<a class="sourceLine" id="cb29-2" data-line-number="2"><span class="co">## the value of the estimated variance</span></a>
<a class="sourceLine" id="cb29-3" data-line-number="3"></a>
<a class="sourceLine" id="cb29-4" data-line-number="4"><span class="co">#as.numeric( VarCorr( lmm.sleep.slope ) )</span></a>
<a class="sourceLine" id="cb29-5" data-line-number="5"></a>
<a class="sourceLine" id="cb29-6" data-line-number="6"><span class="co">#sqrt( as.numeric( VarCorr( lmm.sleep.slope ) ) )</span></a></code></pre></div>
<hr />
<ul>
<li>To get the “BLUPs” of <span class="math inline">\(E(u_{ih}|Y_{i1}, \ldots, Y_{in_{i}})\)</span> of the random effects <span class="math inline">\(u_{i0}\)</span> and <span class="math inline">\(u_{i1}\)</span>,
use <code>ranef</code></li>
</ul>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">blups.slope &lt;-<span class="st"> </span><span class="kw">ranef</span>( lmm.sleep.slope )</a></code></pre></div>
<ul>
<li>To plot these, use <code>dotplot</code> (you will need to load the <code>lattice</code> package first)</li>
</ul>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="kw">library</span>(lattice)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">dotplot</span>(blups.slope)</a></code></pre></div>
<pre><code>## $Subject</code></pre>
<p><img src="01-MixedModels_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb33-1" data-line-number="1"><span class="co">## This plots things sorted by individual-specific estimates of intercepts</span></a></code></pre></div>
<hr />
<ul>
<li>To extract the “predicted” random effects into a <code>DataFrame</code> use</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">ranef.df &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>( blups.slope)</a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="kw">head</span>(ranef.df)</a></code></pre></div>
<pre><code>##    grpvar        term grp    condval   condsd
## 1 Subject (Intercept) 308   2.258551 12.07086
## 2 Subject (Intercept) 309 -40.398738 12.07086
## 3 Subject (Intercept) 310 -38.960409 12.07086
## 4 Subject (Intercept) 330  23.690620 12.07086
## 5 Subject (Intercept) 331  22.260313 12.07086
## 6 Subject (Intercept) 332   9.039568 12.07086</code></pre>
<hr />
<ul>
<li>What we discussed earlier in Section 1.3, were the BLUPs
for <span class="math inline">\(\mathbf{x}_{ij}^{T}\bbeta + \mathbf{z}_{ij}\mathbf{u}_{i}\)</span> not
just the individual components of <span class="math inline">\(\mathbf{u}_{i}\)</span>.</li>
</ul>
<hr />
</div>
</div>
<div id="fitting-binary-glmms-using-the-ohio-data" class="section level3">
<h3><span class="header-section-number">1.5.2</span> Fitting Binary GLMMs using the Ohio data</h3>
<ul>
<li>To use the <strong>ohio</strong> data, we will first load the <strong>geepack</strong> R package:</li>
</ul>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb36-1" data-line-number="1"><span class="kw">library</span>(geepack)</a></code></pre></div>
<ul>
<li>This dataset has 2148 observations from 537 individuals</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb37-1" data-line-number="1"><span class="kw">data</span>(ohio)</a>
<a class="sourceLine" id="cb37-2" data-line-number="2"><span class="kw">head</span>(ohio, <span class="dv">12</span>) <span class="co"># look at first 12 rows of ohio</span></a></code></pre></div>
<pre><code>##    resp id age smoke
## 1     0  0  -2     0
## 2     0  0  -1     0
## 3     0  0   0     0
## 4     0  0   1     0
## 5     0  1  -2     0
## 6     0  1  -1     0
## 7     0  1   0     0
## 8     0  1   1     0
## 9     0  2  -2     0
## 10    0  2  -1     0
## 11    0  2   0     0
## 12    0  2   1     0</code></pre>
<ul>
<li>The outcome of interest in <strong>ohio</strong> is “wheezing status”: 1 - yes, 0 - no.
<ul>
<li>The <strong>resp</strong> variable contains wheezing status.</li>
</ul></li>
<li><p>The <strong>id</strong> variable contains the unique identifier for each individual.</p></li>
<li>The <strong>age</strong> in the <strong>ohio</strong> dataset is the time variable.
<ul>
<li><p>The age variable is recorded as: (<strong>age in years</strong> - 9).</p></li>
<li><p>Each individual starts the study at 7 years of age.</p></li>
</ul></li>
<li><p>The <strong>smoke</strong> variable is an indicator of maternal smoking at the starting year of the study.</p></li>
</ul>
<hr />
<ul>
<li><p>In <strong>lme4</strong>, fitting a GLMM with binary responses can be done with the <strong>glmer</strong> function.</p></li>
<li><p>The <strong>glmer</strong> function has the following syntax:</p></li>
</ul>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="kw">glmer</span>(formula, data, family)</a></code></pre></div>
<ul>
<li><p>The <code>formula</code> argument uses the same syntax as <code>lmer</code></p></li>
<li><p>When handling binary outcomes, you need to specify the family argument as: <code>family = binomial</code>.</p></li>
</ul>
<hr />
<ul>
<li>Put table of proportions here.</li>
</ul>
<div id="a-random-intercept-model" class="section level4">
<h4><span class="header-section-number">1.5.2.1</span> A Random Intercept Model</h4>
<ul>
<li>Let’s use a GLMM to explore the relationship between wheezing status and the:
<ul>
<li><strong>age</strong> of the child</li>
<li>maternal <strong>smoking status</strong></li>
</ul></li>
<li>A GLMM for wheezing status which has age and smoking status as fixed effects and
random individual-specific intercepts can be expressed as</li>
</ul>
<p><span class="math display" id="eq:ohio-intercept">\[\begin{equation}
\textrm{logit}\{ p_{ij}(u_{i}) \}  = \beta_{0} + \beta_{age}\textrm{age}_{ij}
+ \beta_{smk}\textrm{smoke}_{i} + u_{i} 
\tag{1.6}
\end{equation}\]</span></p>
<ul>
<li>Model <a href="mixed-models.html#eq:ohio-intercept">(1.6)</a> can be fit with the following code</li>
</ul>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="co"># id is the grouping variable</span></a>
<a class="sourceLine" id="cb40-2" data-line-number="2">ohio.intercept &lt;-<span class="st"> </span><span class="kw">glmer</span>(resp <span class="op">~</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>smoke <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>id), <span class="dt">data =</span> ohio, <span class="dt">family =</span> binomial)</a></code></pre></div>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="kw">coef</span>(<span class="kw">summary</span>(ohio.intercept))</a></code></pre></div>
<pre><code>##               Estimate Std. Error    z value     Pr(&gt;|z|)
## (Intercept) -3.3739539 0.27497502 -12.270038 1.311914e-34
## age         -0.1767645 0.06796698  -2.600741 9.302258e-03
## smoke        0.4147806 0.28704052   1.445024 1.484510e-01</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">VarCorr</span>(ohio.intercept)</a></code></pre></div>
<pre><code>##  Groups Name        Std.Dev.
##  id     (Intercept) 2.3432</code></pre>
<hr />
<ul>
<li>Plotting</li>
</ul>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1">beta.hat &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(ohio.intercept))[,<span class="dv">1</span>]</a>
<a class="sourceLine" id="cb45-2" data-line-number="2">age.vec &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb45-3" data-line-number="3"><span class="kw">plot</span>(<span class="dv">0</span>,<span class="dv">0</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">las=</span><span class="dv">1</span>,</a>
<a class="sourceLine" id="cb45-4" data-line-number="4">     <span class="dt">xlab =</span> <span class="st">&quot;Age in Years - 9 Years&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Wheezing Probability&quot;</span>)</a>
<a class="sourceLine" id="cb45-5" data-line-number="5"><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">50</span>) {</a>
<a class="sourceLine" id="cb45-6" data-line-number="6">  u.draw1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="fl">2.34</span>)</a>
<a class="sourceLine" id="cb45-7" data-line-number="7">  u.draw2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, <span class="dt">mean=</span><span class="dv">0</span>, <span class="dt">sd=</span><span class="fl">2.34</span>)</a>
<a class="sourceLine" id="cb45-8" data-line-number="8">  <span class="kw">lines</span>(age.vec, <span class="kw">plogis</span>(u.draw1 <span class="op">+</span><span class="st"> </span>beta.hat[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>beta.hat[<span class="dv">2</span>]<span class="op">*</span>age.vec <span class="op">+</span><span class="st"> </span>beta.hat[<span class="dv">3</span>]))</a>
<a class="sourceLine" id="cb45-9" data-line-number="9">  <span class="kw">lines</span>(age.vec, <span class="kw">plogis</span>(u.draw2 <span class="op">+</span><span class="st"> </span>beta.hat[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>beta.hat[<span class="dv">2</span>]<span class="op">*</span>age.vec), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb45-10" data-line-number="10">}</a></code></pre></div>
<p><img src="01-MixedModels_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<hr />

<div id="refs" class="references">
<div>
<p>Diggle, Peter, Patrick Heagerty, Kung-Yee Liang, and Scott Zeger. 2013. <em>Analysis of Longitudinal Data</em>. Vol. 25.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-diggle2013">
<p>Diggle, Peter, Patrick Heagerty, Kung-Yee Liang, and Scott Zeger. 2013. <em>Analysis of Longitudinal Data</em>. Vol. 25.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
