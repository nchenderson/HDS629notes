<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Nonparametric Regression with Longitudinal Data | Notes for Case Studies in Health Big Data</title>
  <meta name="description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Nonparametric Regression with Longitudinal Data | Notes for Case Studies in Health Big Data" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://nchenderson.github.io/HDS629notes/" />
  
  <meta property="og:description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  <meta name="github-repo" content="nchenderson/HDS629notes" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Nonparametric Regression with Longitudinal Data | Notes for Case Studies in Health Big Data" />
  
  <meta name="twitter:description" content="Course notes for Biostatistics 629: Case Studies in Health Big Data" />
  

<meta name="author" content="Nicholas Henderson" />


<meta name="date" content="2021-04-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="missing-data.html"/>
<link rel="next" href="glmm-lasso.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Biostat 629</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>1</b> Mixed Models for Longitudinal Data Analysis</a><ul>
<li class="chapter" data-level="1.1" data-path="mixed-models.html"><a href="mixed-models.html#sec:methods-overview"><i class="fa fa-check"></i><b>1.1</b> Methods for Analyzing Longitudinal Data</a></li>
<li class="chapter" data-level="1.2" data-path="mixed-models.html"><a href="mixed-models.html#mixed-models-for-continuous-outcomes"><i class="fa fa-check"></i><b>1.2</b> Mixed Models for Continuous Outcomes</a></li>
<li class="chapter" data-level="1.3" data-path="mixed-models.html"><a href="mixed-models.html#advantages-of-using-random-effects"><i class="fa fa-check"></i><b>1.3</b> Advantages of using random effects</a><ul>
<li class="chapter" data-level="1.3.1" data-path="mixed-models.html"><a href="mixed-models.html#within-subject-correlation"><i class="fa fa-check"></i><b>1.3.1</b> Within-subject correlation</a></li>
<li class="chapter" data-level="1.3.2" data-path="mixed-models.html"><a href="mixed-models.html#inference-about-heterogeneity---variance-of-random-effects"><i class="fa fa-check"></i><b>1.3.2</b> Inference about Heterogeneity - Variance of Random Effects</a></li>
<li class="chapter" data-level="1.3.3" data-path="mixed-models.html"><a href="mixed-models.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>1.3.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="mixed-models.html"><a href="mixed-models.html#generalized-linear-mixed-models-glmms"><i class="fa fa-check"></i><b>1.4</b> Generalized linear mixed models (GLMMs)</a><ul>
<li class="chapter" data-level="1.4.1" data-path="mixed-models.html"><a href="mixed-models.html#glmms-with-binary-outcomes"><i class="fa fa-check"></i><b>1.4.1</b> GLMMs with Binary Outcomes</a></li>
<li class="chapter" data-level="1.4.2" data-path="mixed-models.html"><a href="mixed-models.html#glmms-with-count-outcomes"><i class="fa fa-check"></i><b>1.4.2</b> GLMMs with Count Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="mixed-models.html"><a href="mixed-models.html#fitting-linear-mixed-models-lmms-and-generalized-linear-mixed-models-glmms-in-r"><i class="fa fa-check"></i><b>1.5</b> Fitting Linear Mixed Models (LMMs) and Generalized Linear Mixed models (GLMMs) in <strong>R</strong></a><ul>
<li class="chapter" data-level="1.5.1" data-path="mixed-models.html"><a href="mixed-models.html#fitting-lmms-with-the-sleepstudy-data"><i class="fa fa-check"></i><b>1.5.1</b> Fitting LMMs with the sleepstudy data</a></li>
<li class="chapter" data-level="1.5.2" data-path="mixed-models.html"><a href="mixed-models.html#fitting-binary-glmms-using-the-ohio-data"><i class="fa fa-check"></i><b>1.5.2</b> Fitting Binary GLMMs using the Ohio data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="missing-data.html"><a href="missing-data.html"><i class="fa fa-check"></i><b>2</b> Missing Data and Multiple Imputation</a><ul>
<li class="chapter" data-level="2.1" data-path="missing-data.html"><a href="missing-data.html#missing-data-in-r-and-direct-approaches-for-handling-missing-data"><i class="fa fa-check"></i><b>2.1</b> Missing Data in R and “Direct Approaches” for Handling Missing Data</a><ul>
<li class="chapter" data-level="2.1.1" data-path="missing-data.html"><a href="missing-data.html#complete-case-analysis-listwise-deletion"><i class="fa fa-check"></i><b>2.1.1</b> Complete Case Analysis (Listwise Deletion)</a></li>
<li class="chapter" data-level="2.1.2" data-path="missing-data.html"><a href="missing-data.html#other-direct-methods"><i class="fa fa-check"></i><b>2.1.2</b> Other “Direct” Methods</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="missing-data.html"><a href="missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>2.2</b> Multiple Imputation</a><ul>
<li class="chapter" data-level="2.2.1" data-path="missing-data.html"><a href="missing-data.html#short-overview-of-multiple-imputation"><i class="fa fa-check"></i><b>2.2.1</b> Short Overview of Multiple Imputation</a></li>
<li class="chapter" data-level="2.2.2" data-path="missing-data.html"><a href="missing-data.html#multiple-imputation-with-mice"><i class="fa fa-check"></i><b>2.2.2</b> Multiple imputation with mice</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="missing-data.html"><a href="missing-data.html#what-is-mice-doing"><i class="fa fa-check"></i><b>2.3</b> What is MICE doing?</a></li>
<li class="chapter" data-level="2.4" data-path="missing-data.html"><a href="missing-data.html#longitudinal-data"><i class="fa fa-check"></i><b>2.4</b> Longitudinal Data</a></li>
<li class="chapter" data-level="2.5" data-path="missing-data.html"><a href="missing-data.html#different-missing-data-mechanisms"><i class="fa fa-check"></i><b>2.5</b> Different Missing Data Mechanisms</a><ul>
<li class="chapter" data-level="2.5.1" data-path="missing-data.html"><a href="missing-data.html#missing-completely-at-random-mcar"><i class="fa fa-check"></i><b>2.5.1</b> Missing Completely at Random (MCAR)</a></li>
<li class="chapter" data-level="2.5.2" data-path="missing-data.html"><a href="missing-data.html#missing-at-random-mar"><i class="fa fa-check"></i><b>2.5.2</b> Missing at Random (MAR)</a></li>
<li class="chapter" data-level="2.5.3" data-path="missing-data.html"><a href="missing-data.html#missing-not-at-random-mnar"><i class="fa fa-check"></i><b>2.5.3</b> Missing not at Random (MNAR)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonpar-regression.html"><a href="nonpar-regression.html"><i class="fa fa-check"></i><b>3</b> Nonparametric Regression with Longitudinal Data</a><ul>
<li class="chapter" data-level="3.1" data-path="nonpar-regression.html"><a href="nonpar-regression.html#notation"><i class="fa fa-check"></i><b>3.1</b> Notation</a></li>
<li class="chapter" data-level="3.2" data-path="nonpar-regression.html"><a href="nonpar-regression.html#kernel-smoothing"><i class="fa fa-check"></i><b>3.2</b> Kernel Smoothing</a><ul>
<li class="chapter" data-level="3.2.1" data-path="nonpar-regression.html"><a href="nonpar-regression.html#description-of-kernel-regression"><i class="fa fa-check"></i><b>3.2.1</b> Description of Kernel Regression</a></li>
<li class="chapter" data-level="3.2.2" data-path="nonpar-regression.html"><a href="nonpar-regression.html#kernel-regression-in-the-sleepstudy-data"><i class="fa fa-check"></i><b>3.2.2</b> Kernel Regression in the sleepstudy data</a></li>
<li class="chapter" data-level="3.2.3" data-path="nonpar-regression.html"><a href="nonpar-regression.html#bandwidth-selection"><i class="fa fa-check"></i><b>3.2.3</b> Bandwidth Selection</a></li>
<li class="chapter" data-level="3.2.4" data-path="nonpar-regression.html"><a href="nonpar-regression.html#another-example-the-bone-data"><i class="fa fa-check"></i><b>3.2.4</b> Another Example: The Bone Data</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="nonpar-regression.html"><a href="nonpar-regression.html#regression-splines"><i class="fa fa-check"></i><b>3.3</b> Regression Splines</a><ul>
<li class="chapter" data-level="3.3.1" data-path="nonpar-regression.html"><a href="nonpar-regression.html#overview"><i class="fa fa-check"></i><b>3.3.1</b> Overview</a></li>
<li class="chapter" data-level="3.3.2" data-path="nonpar-regression.html"><a href="nonpar-regression.html#regression-splines-with-longitudinal-data-in-r"><i class="fa fa-check"></i><b>3.3.2</b> Regression Splines with Longitudinal Data in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="glmm-lasso.html"><a href="glmm-lasso.html"><i class="fa fa-check"></i><b>4</b> Sparse Regression for Longitudinal Data</a><ul>
<li class="chapter" data-level="4.1" data-path="glmm-lasso.html"><a href="glmm-lasso.html#sparse-regression-methods"><i class="fa fa-check"></i><b>4.1</b> Sparse regression methods</a></li>
<li class="chapter" data-level="4.2" data-path="glmm-lasso.html"><a href="glmm-lasso.html#the-lasso-with-longitudinal-data"><i class="fa fa-check"></i><b>4.2</b> The Lasso with longitudinal data</a></li>
<li class="chapter" data-level="4.3" data-path="glmm-lasso.html"><a href="glmm-lasso.html#lasso-for-lmms-and-glmms-in-r"><i class="fa fa-check"></i><b>4.3</b> Lasso for LMMs and GLMMs in R</a><ul>
<li class="chapter" data-level="4.3.1" data-path="glmm-lasso.html"><a href="glmm-lasso.html#soccer-data"><i class="fa fa-check"></i><b>4.3.1</b> Soccer Data</a></li>
<li class="chapter" data-level="4.3.2" data-path="glmm-lasso.html"><a href="glmm-lasso.html#choosing-the-tuning-parameter-for-the-soccer-data"><i class="fa fa-check"></i><b>4.3.2</b> Choosing the tuning parameter for the soccer data</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="glmm-lasso.html"><a href="glmm-lasso.html#cross-validation-for-longitudinal-data"><i class="fa fa-check"></i><b>4.4</b> Cross-Validation for Longitudinal Data</a></li>
<li class="chapter" data-level="4.5" data-path="glmm-lasso.html"><a href="glmm-lasso.html#glmm-lasso-with-binary-outcomes"><i class="fa fa-check"></i><b>4.5</b> GLMM-Lasso with Binary Outcomes</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="risk-prediction.html"><a href="risk-prediction.html"><i class="fa fa-check"></i><b>5</b> Risk Prediction and Validation</a><ul>
<li class="chapter" data-level="5.1" data-path="risk-prediction.html"><a href="risk-prediction.html#risk-predictionstratification"><i class="fa fa-check"></i><b>5.1</b> Risk Prediction/Stratification</a></li>
<li class="chapter" data-level="5.2" data-path="risk-prediction.html"><a href="risk-prediction.html#area-under-the-roc-curve-and-the-c-statistic"><i class="fa fa-check"></i><b>5.2</b> Area under the ROC curve and the C-statistic</a><ul>
<li class="chapter" data-level="5.2.1" data-path="risk-prediction.html"><a href="risk-prediction.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>5.2.1</b> Sensitivity and Specificity</a></li>
<li class="chapter" data-level="5.2.2" data-path="risk-prediction.html"><a href="risk-prediction.html#the-roc-curve"><i class="fa fa-check"></i><b>5.2.2</b> The ROC curve</a></li>
<li class="chapter" data-level="5.2.3" data-path="risk-prediction.html"><a href="risk-prediction.html#computing-the-roc-curve"><i class="fa fa-check"></i><b>5.2.3</b> Computing the ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="risk-prediction.html"><a href="risk-prediction.html#area-under-the-roc-curve"><i class="fa fa-check"></i><b>5.3</b> Area under the ROC curve</a><ul>
<li class="chapter" data-level="5.3.1" data-path="risk-prediction.html"><a href="risk-prediction.html#rewriting-the-formula-for-the-auc"><i class="fa fa-check"></i><b>5.3.1</b> Rewriting the formula for the AUC</a></li>
<li class="chapter" data-level="5.3.2" data-path="risk-prediction.html"><a href="risk-prediction.html#interpreting-the-auc"><i class="fa fa-check"></i><b>5.3.2</b> Interpreting the AUC</a></li>
<li class="chapter" data-level="5.3.3" data-path="risk-prediction.html"><a href="risk-prediction.html#computing-the-auc-in-r"><i class="fa fa-check"></i><b>5.3.3</b> Computing the AUC in R</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="risk-prediction.html"><a href="risk-prediction.html#calibration"><i class="fa fa-check"></i><b>5.4</b> Calibration</a></li>
<li class="chapter" data-level="5.5" data-path="risk-prediction.html"><a href="risk-prediction.html#longitudinal-data-and-risk-score-validation"><i class="fa fa-check"></i><b>5.5</b> Longitudinal Data and Risk Score Validation</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for Case Studies in Health Big Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonpar-regression" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Nonparametric Regression with Longitudinal Data</h1>
<div id="notation" class="section level2">
<h2><span class="header-section-number">3.1</span> Notation</h2>
<ul>
<li>For <strong>longitudinal data</strong>, we will again use the following <strong>notation</strong>:
<ul>
<li><p>Individual <span class="math inline">\(i\)</span> has observations for both the outcome and the covariates at times <span class="math inline">\(t_{i1}, \ldots, t_{in_{i}}\)</span></p></li>
<li><p><span class="math inline">\(Y_{ij}\)</span> is the outcome for individual <span class="math inline">\(i\)</span> at time <span class="math inline">\(t_{ij}\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{x}_{ij}\)</span> is the vector of covariates at time <span class="math inline">\(t_{ij}\)</span>.</p></li>
<li><p>The <span class="math inline">\(i^{th}\)</span> individual has <span class="math inline">\(n_{i}\)</span> observations: <span class="math inline">\(Y_{i1}, \ldots, Y_{in_{i}}\)</span>.</p></li>
<li><p>There will be <span class="math inline">\(m\)</span> individuals in the study (so <span class="math inline">\(1 \leq i \leq m\)</span>).</p></li>
</ul></li>
<li><p>A general regression model relating <span class="math inline">\(Y_{ij}\)</span> and <span class="math inline">\(\mathbf{x}_{ij}\)</span> is the following:
<span class="math display">\[\begin{equation}
Y_{ij} = \mu( \mathbf{x}_{ij} ) + \varepsilon_{ij}  \nonumber
\end{equation}\]</span></p></li>
<li><p>Here, <span class="math inline">\(\mu(\mathbf{x}_{ij}) = E(Y_{ij}| \mathbf{x}_{ij})\)</span> is the “mean function”.</p></li>
<li><p>In <strong>nonparametric approaches</strong> to estimating <span class="math inline">\(\mu(\cdot)\)</span>, we will try to estimate <span class="math inline">\(\mu(\mathbf{x})\)</span> without
making any strong assumptions about the form of <span class="math inline">\(\mu( \mathbf{x} )\)</span>.</p></li>
<li><p>Basically, in a nonparametric approach, there is not a fixed set of parameters describing
the mean function that does not change as the sample size grows.</p></li>
</ul>
</div>
<div id="kernel-smoothing" class="section level2">
<h2><span class="header-section-number">3.2</span> Kernel Smoothing</h2>
<div id="description-of-kernel-regression" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Description of Kernel Regression</h3>
<ul>
<li><p>With <strong>kernel regression</strong>, we estimate the mean function <span class="math inline">\(\mu(\mathbf{x})\)</span> at <span class="math inline">\(\mathbf{x}\)</span>
by taking a weighted <strong>“local average”</strong> of the <span class="math inline">\(Y_{ij}\)</span> around <span class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p>Specifically, the <strong>kernel regression estimate</strong> of <span class="math inline">\(\mu(\cdot)\)</span> at a point <span class="math inline">\(\mathbf{x}\)</span> can be expressed as
<span class="math display">\[\begin{equation}
\hat{\mu}( \mathbf{x} ) = \sum_{i=1}^{m}\sum_{j=1}^{n_{i}} w_{ij}(\mathbf{x})Y_{ij} 
\end{equation}\]</span></p></li>
<li><p>The <strong>“weights”</strong> at the point <span class="math inline">\(\mathbf{x}\)</span> are given by
<span class="math display" id="eq:nw-weights">\[\begin{equation}
w_{ij}(\mathbf{x}) = \frac{ K\Big( \frac{\mathbf{x} - \mathbf{x}_{ij}}{ h_{n} }\Big) }{ \sum_{i=1}^{m}\sum_{j=1}^{n_{i}} K\Big( \frac{\mathbf{x} - \mathbf{x}_{ij}}{ h_{n} }\Big)  }
\tag{3.1}
\end{equation}\]</span></p></li>
<li><p>When using the weights <a href="nonpar-regression.html#eq:nw-weights">(3.1)</a>, <span class="math inline">\(\hat{\mu}(\mathbf{x})\)</span> is known as the <strong>Nadaraya-Watson</strong> esitmator.</p></li>
</ul>
<hr />
<ul>
<li><p>The function <span class="math inline">\(K(\cdot)\)</span> in <a href="nonpar-regression.html#eq:nw-weights">(3.1)</a> is referred to as the <strong>“kernel function”</strong>.</p></li>
<li>The <strong>kernel function</strong> <span class="math inline">\(K(\cdot)\)</span> is:
<ul>
<li>A smooth nonnegative function</li>
<li>Symmetric around <span class="math inline">\(0\)</span></li>
<li>Has a mode at <span class="math inline">\(0\)</span> and decays the further you go away from <span class="math inline">\(0\)</span></li>
</ul></li>
<li><p>A common choice of <span class="math inline">\(K(\cdot)\)</span> is the <strong>Gaussian kernel</strong>
<span class="math display">\[\begin{equation}
K(\mathbf{u}) = \exp\Big\{ - \frac{||\mathbf{u}||^{2}}{2} \Big\}
\end{equation}\]</span></p></li>
</ul>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<hr />
<ul>
<li><p>Observations where <span class="math inline">\(\mathbf{x}_{ij}\)</span> is <strong>“close”</strong> to <span class="math inline">\(\mathbf{x}\)</span> will be given
a larger weight <span class="math inline">\(w_{ij}(\mathbf{x})\)</span> because <span class="math inline">\(||\mathbf{x} - \mathbf{x}_{ij}||^{2}\)</span> will be small.</p></li>
<li><p>Similarly, observations where <span class="math inline">\(\mathbf{x}_{ij}\)</span> is <strong>“far away”</strong> from <span class="math inline">\(\mathbf{x}\)</span> will be given
a smaller weight <span class="math inline">\(w_{ij}(\mathbf{x})\)</span> because <span class="math inline">\(||\mathbf{x} - \mathbf{x}_{ij}||^{2}\)</span> will be small.</p></li>
</ul>
<hr />
<ul>
<li><p>The term <span class="math inline">\(h_{n} &gt; 0\)</span> is referred to as the <strong>bandwidth</strong>.</p></li>
<li><p>The <strong>bandwidth</strong> determines how many observations have
a strong impact on the value of <span class="math inline">\(\hat{\mu}( \mathbf{x} )\)</span>.</p></li>
<li><p>If the bandwidth <span class="math inline">\(h_{n}\)</span> is <strong>small</strong>, observations close to <span class="math inline">\(\mathbf{x}\)</span> will largely
determine the value of <span class="math inline">\(\hat{\mu}(\mathbf{x})\)</span>.</p></li>
<li><p>If the bandwidth <span class="math inline">\(h_{n}\)</span> is <strong>large</strong>, the value of <span class="math inline">\(\hat{\mu}(\mathbf{x})\)</span> will be more heavily influenced
by a larger number of observations.</p></li>
</ul>
<hr />
<ul>
<li><p>Kernel regression estimates with a <strong>smaller bandwidth</strong> will be more “wiggly” and <strong>non-smooth</strong>.</p></li>
<li><p>Kernel regression estimates with a <strong>larger bandwidth</strong> will be more <strong>smooth</strong>.</p></li>
</ul>
</div>
<div id="kernel-regression-in-the-sleepstudy-data" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Kernel Regression in the sleepstudy data</h3>
<ul>
<li><p>Again, let’s look at the <strong>sleepstudy</strong> data from the <strong>lme4</strong> package.</p></li>
<li><p>The <strong>sleepstudy</strong> data had 18 participants with <strong>reaction time</strong>
measured across 10 days.</p></li>
</ul>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb120-1" data-line-number="1"><span class="kw">library</span>(lme4)</a></code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb122-1" data-line-number="1"><span class="kw">data</span>(sleepstudy)</a>
<a class="sourceLine" id="cb122-2" data-line-number="2"><span class="kw">head</span>(sleepstudy)</a></code></pre></div>
<pre><code>##   Reaction Days Subject
## 1 249.5600    0     308
## 2 258.7047    1     308
## 3 250.8006    2     308
## 4 321.4398    3     308
## 5 356.8519    4     308
## 6 414.6901    5     308</code></pre>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<hr />
<ul>
<li><p>We can estimate the <strong>marginal mean function</strong> for the <strong>sleepstudy</strong> data by using a <strong>GEE</strong>.</p></li>
<li>We will assume that reaction time is a <strong>linear function</strong> of time on study:
<ul>
<li>That is, we will assume that <span class="math inline">\(\mu(t) = \beta_{0} + \beta_{1} t\)</span>.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb124-1" data-line-number="1"><span class="kw">library</span>(geepack)</a>
<a class="sourceLine" id="cb124-2" data-line-number="2"><span class="co">## Use AR(1) correlation structure</span></a>
<a class="sourceLine" id="cb124-3" data-line-number="3">sleep.gee &lt;-<span class="st"> </span><span class="kw">geeglm</span>(Reaction <span class="op">~</span><span class="st"> </span>Days, <span class="dt">data=</span>sleepstudy, <span class="dt">id=</span>Subject, <span class="dt">corstr=</span><span class="st">&quot;ar1&quot;</span>) </a></code></pre></div>
<ul>
<li>To get the value of the estimated <strong>regression function</strong>, we can use the first
<span class="math inline">\(10\)</span> fitted values (because the fitted values for each subject are the same as the overall mean function)</li>
</ul>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb125-1" data-line-number="1"><span class="co">## Estimated mean function at each time point</span></a>
<a class="sourceLine" id="cb125-2" data-line-number="2">gee.regfn &lt;-<span class="st"> </span>sleep.gee<span class="op">$</span>fitted.values[<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>,<span class="dv">1</span>] </a>
<a class="sourceLine" id="cb125-3" data-line-number="3"></a>
<a class="sourceLine" id="cb125-4" data-line-number="4"><span class="co">### Now plot the estimated mean function</span></a>
<a class="sourceLine" id="cb125-5" data-line-number="5"><span class="kw">plot</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylab=</span><span class="st">&quot;Reaction Time&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Days&quot;</span>,</a>
<a class="sourceLine" id="cb125-6" data-line-number="6">     <span class="dt">main=</span><span class="st">&quot;Sleepstudy: GEE estimate of Mean Function&quot;</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb125-7" data-line-number="7"><span class="kw">points</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb125-8" data-line-number="8"><span class="kw">lines</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">9</span>, gee.regfn, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<hr />
<ul>
<li><p>To find a kernel regression estimate of the mean function, you can use the <strong>ksmooth</strong> function in <strong>R</strong>.</p></li>
<li><p>One thing to note is that <strong>ksmooth</strong> only works for a scalar covariate.</p></li>
<li><p>Using a <strong>bandwidth</strong> of <span class="math inline">\(0.5\)</span> and a <strong>Gaussian kernel</strong>, we can find the kernel regression estimate of the mean function
with the following <strong>R</strong> code:</p></li>
</ul>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb126-1" data-line-number="1">sleep.kernel &lt;-<span class="st"> </span><span class="kw">ksmooth</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">kernel=</span><span class="st">&quot;normal&quot;</span>,</a>
<a class="sourceLine" id="cb126-2" data-line-number="2">                        <span class="dt">bandwidth =</span> <span class="fl">0.5</span>)</a></code></pre></div>
<ul>
<li><p>This will return a list with an “x vector” and a “y vector”.</p></li>
<li><p>The <code>x</code> vector will be the vector of points at which the regression function
is estimated. The <code>y</code> vector will be a vector containing the estimated values of the regression function.</p></li>
</ul>
<hr />
<ul>
<li>Let’s <strong>plot</strong> the estimated mean function to see what it looks like:</li>
</ul>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb127-1" data-line-number="1"><span class="kw">plot</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylab=</span><span class="st">&quot;Reaction Time&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Days&quot;</span>,</a>
<a class="sourceLine" id="cb127-2" data-line-number="2">     <span class="dt">main=</span><span class="st">&quot;Sleepstudy: Kernel Regression with Bandwidth = 0.5&quot;</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb127-3" data-line-number="3"><span class="kw">points</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb127-4" data-line-number="4"><span class="kw">lines</span>(sleep.kernel<span class="op">$</span>x, sleep.kernel<span class="op">$</span>y, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<ul>
<li><p>This <strong>bandwidth</strong> looks too small. There are clear “near jumps” in between
some of the days.</p></li>
<li><p>We can try a <strong>bandwidth</strong> of <span class="math inline">\(1\)</span> to see if we can smooth this out a bit.</p></li>
</ul>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb128-1" data-line-number="1">sleep.kernel.bw1 &lt;-<span class="st"> </span><span class="kw">ksmooth</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">kernel=</span><span class="st">&quot;normal&quot;</span>,</a>
<a class="sourceLine" id="cb128-2" data-line-number="2">                        <span class="dt">bandwidth =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb128-3" data-line-number="3"></a>
<a class="sourceLine" id="cb128-4" data-line-number="4"><span class="kw">plot</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylab=</span><span class="st">&quot;Reaction Time&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;Days&quot;</span>,</a>
<a class="sourceLine" id="cb128-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;Sleepstudy: Kernel Regression with Bandwidth = 1&quot;</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb128-6" data-line-number="6"><span class="kw">points</span>(sleepstudy<span class="op">$</span>Days, sleepstudy<span class="op">$</span>Reaction, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb128-7" data-line-number="7"><span class="kw">lines</span>(sleep.kernel.bw1<span class="op">$</span>x, sleep.kernel.bw1<span class="op">$</span>y, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="bandwidth-selection" class="section level3">
<h3><span class="header-section-number">3.2.3</span> Bandwidth Selection</h3>
<ul>
<li><p>The bandwidth can be chosen to get a level of smoothness that looks good visually.</p></li>
<li><p>For example, when observations are only collected daily like in the <strong>sleepstudy</strong>
you will probably want to choose a bandwidth so that the estimated mean function
does not have obvious bumps in between days.</p></li>
</ul>
<hr />
<ul>
<li><p>To choose the bandwidth <span class="math inline">\(h_{n} &gt; 0\)</span> using a formal criterion, a common approach is
to use <strong>leave-one-out</strong> cross-validation.</p></li>
<li><p>In the context of <strong>longitudinal data</strong>, it is usually suggested that you
leave one <strong>subject</strong> out at a time rather than one <strong>observation</strong> at a time (<span class="citation">Rice and Silverman (<a href="#ref-rice1991">1991</a>)</span>).</p></li>
<li><p>The reason for this is that the <strong>subject-level leave-one-out cross-validation</strong> score is
a good estimate of the <strong>mean-squared prediction error</strong> of regardless of what the
correlation structure is for the within-subject outcomes.</p></li>
<li><p>This is not the case when using <strong>observation-level leave-one-out cross-validation</strong>.</p></li>
</ul>
<hr />
<ul>
<li><p>The <strong>subject-level leave-one-out cross-validation score</strong> for a given bandwidth choice is
defined as
<span class="math display">\[\begin{equation}
\textrm{LOOCV}(h_{n}) = \sum_{i=1}^{n}\sum_{j=1}^{m_{i}} \{ Y_{ij} - \hat{\mu}_{h_{n}}^{(-i)}(\mathbf{x}_{ij}) \}^{2}
\end{equation}\]</span></p></li>
<li><p>Here, <span class="math inline">\(\hat{\mu}_{h_{n}}^{(-i)}(\mathbf{x}_{ij})\)</span> is the mean function estimate when using
<strong>bandwidth</strong> <span class="math inline">\(h_{n}\)</span> and when ignoring the data from subject <span class="math inline">\(i\)</span>.</p></li>
</ul>
</div>
<div id="another-example-the-bone-data" class="section level3">
<h3><span class="header-section-number">3.2.4</span> Another Example: The Bone Data</h3>
<ul>
<li><p>As another example, we can use the “bone” dataset.</p></li>
<li><p>This is a <strong>longitudinal dataset</strong> with typically 2 or 3 observations per individual.</p></li>
</ul>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb129-1" data-line-number="1">bonedat &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;https://web.stanford.edu/~hastie/ElemStatLearn/datasets/bone.data&quot;</span>, </a>
<a class="sourceLine" id="cb129-2" data-line-number="2">                      <span class="dt">header=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb129-3" data-line-number="3"><span class="kw">head</span>(bonedat)</a></code></pre></div>
<pre><code>##   idnum   age gender      spnbmd
## 1     1 11.70   male 0.018080670
## 2     1 12.70   male 0.060109290
## 3     1 13.75   male 0.005857545
## 4     2 13.25   male 0.010263930
## 5     2 14.30   male 0.210526300
## 6     2 15.30   male 0.040843210</code></pre>
<ul>
<li>For this data, the interest would be to model the mean function for bone mineral
density (the variable <code>spnbmd</code>) as a function of <code>age</code></li>
</ul>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<hr />
<ul>
<li>We can compute the leave-one-out cross-validation score for the <strong>bone</strong> data
for <strong>different</strong> values of <span class="math inline">\(h_{n}\)</span> (here <span class="math inline">\(0.1 \leq h_{n} \leq 1\)</span>) with the following code:</li>
</ul>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb131-1" data-line-number="1">nh &lt;-<span class="st"> </span><span class="dv">200</span></a>
<a class="sourceLine" id="cb131-2" data-line-number="2">hh &lt;-<span class="st"> </span><span class="kw">seq</span>(.<span class="dv">1</span>, <span class="dv">1</span>, <span class="dt">length.out=</span>nh)</a>
<a class="sourceLine" id="cb131-3" data-line-number="3">LOOCV &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, nh)</a>
<a class="sourceLine" id="cb131-4" data-line-number="4">subj.list &lt;-<span class="st"> </span><span class="kw">unique</span>(bonedat<span class="op">$</span>idnum)</a>
<a class="sourceLine" id="cb131-5" data-line-number="5">nsubj &lt;-<span class="st"> </span><span class="kw">length</span>(subj.list)</a>
<a class="sourceLine" id="cb131-6" data-line-number="6"><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nh) {</a>
<a class="sourceLine" id="cb131-7" data-line-number="7">    ss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb131-8" data-line-number="8">    <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nsubj) {</a>
<a class="sourceLine" id="cb131-9" data-line-number="9">        ind &lt;-<span class="st"> </span>bonedat<span class="op">$</span>idnum<span class="op">==</span>subj.list[i]</a>
<a class="sourceLine" id="cb131-10" data-line-number="10">        yy &lt;-<span class="st"> </span>bonedat<span class="op">$</span>spnbmd[<span class="op">-</span>ind]</a>
<a class="sourceLine" id="cb131-11" data-line-number="11">        xx &lt;-<span class="st"> </span>bonedat<span class="op">$</span>age[<span class="op">-</span>ind]</a>
<a class="sourceLine" id="cb131-12" data-line-number="12">        tmp &lt;-<span class="st"> </span><span class="kw">ksmooth</span>(xx, yy, <span class="dt">kernel=</span><span class="st">&quot;normal&quot;</span>, <span class="dt">bandwidth =</span> hh[k],</a>
<a class="sourceLine" id="cb131-13" data-line-number="13">                       <span class="dt">x.points=</span>bonedat<span class="op">$</span>age[ind])</a>
<a class="sourceLine" id="cb131-14" data-line-number="14">        mu.hat &lt;-<span class="st"> </span>tmp<span class="op">$</span>y</a>
<a class="sourceLine" id="cb131-15" data-line-number="15">        ss &lt;-<span class="st"> </span>ss <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>((bonedat<span class="op">$</span>spnbmd[ind] <span class="op">-</span><span class="st"> </span>mu.hat)<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb131-16" data-line-number="16">    }</a>
<a class="sourceLine" id="cb131-17" data-line-number="17">    LOOCV[k] &lt;-<span class="st"> </span>ss</a>
<a class="sourceLine" id="cb131-18" data-line-number="18">}</a>
<a class="sourceLine" id="cb131-19" data-line-number="19">hh[<span class="kw">which.min</span>(LOOCV)] <span class="co">## best seems to be 0.1</span></a></code></pre></div>
<pre><code>## [1] 0.1</code></pre>
<ul>
<li>In this case, the best <strong>bandwidth</strong> was <span class="math inline">\(0.1\)</span> according to the
subject-level leave-one-out cross-validation criterion.</li>
</ul>
<hr />
<ul>
<li>The kernel regression estimate of the mean function with the bandwidth of <span class="math inline">\(0.1\)</span> is plotted below:</li>
</ul>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb133-1" data-line-number="1">bone.kernel &lt;-<span class="st"> </span><span class="kw">ksmooth</span>(bonedat<span class="op">$</span>age, bonedat<span class="op">$</span>spnbmd, <span class="dt">kernel=</span><span class="st">&quot;normal&quot;</span>,</a>
<a class="sourceLine" id="cb133-2" data-line-number="2">                        <span class="dt">bandwidth =</span> <span class="fl">0.1</span>, <span class="dt">x.points=</span><span class="kw">seq</span>(<span class="fl">9.4</span>, <span class="dv">25</span>, <span class="dt">length.out=</span><span class="dv">100</span>))</a>
<a class="sourceLine" id="cb133-3" data-line-number="3"></a>
<a class="sourceLine" id="cb133-4" data-line-number="4"><span class="kw">plot</span>(bonedat<span class="op">$</span>age, bonedat<span class="op">$</span>spnbmd, <span class="dt">las=</span><span class="dv">1</span>, <span class="dt">ylab=</span><span class="st">&quot;spnbmd&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;age&quot;</span>,</a>
<a class="sourceLine" id="cb133-5" data-line-number="5">     <span class="dt">main=</span><span class="st">&quot;Bone Data: Kernel Regression with Bandwidth = 0.1&quot;</span>, <span class="dt">type=</span><span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb133-6" data-line-number="6"><span class="kw">points</span>(bonedat<span class="op">$</span>age, bonedat<span class="op">$</span>spnbmd, <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb133-7" data-line-number="7"><span class="kw">lines</span>(bone.kernel<span class="op">$</span>x, bone.kernel<span class="op">$</span>y, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<ul>
<li>Using a bandwidth of <span class="math inline">\(1\)</span> gives a smoother mean function estimate.
<img src="03-NonParRegression_files/figure-html/unnamed-chunk-13-1.png" width="672" /></li>
</ul>
<hr />
<ul>
<li><p>The performance of kernel regression methods can degrade quickly as we move to higher dimensions.
The convergence rate of the estimated regression function to the true regression function slows substantially
as we the dimension of the covariates <span class="math inline">\(\mathbf{x}_{ij}\)</span>.</p></li>
<li><p>“Curse of dimensionality” - need very large datasets to have a sufficient number of observations
near a given point <span class="math inline">\(\mathbf{x}\)</span>.</p></li>
<li><p>Another approach when using multiple covariates is to use <strong>generalized additive models.</strong></p></li>
<li><p>With <strong>generalized additive models</strong>, the mean function is expressed
as the sum of several univariate nonparametric functions:
<span class="math display">\[\begin{equation}
\mu(\mathbf{x}) = \beta_{0} + \mu(x_{1}) + \mu(x_{2}) + \ldots + \mu(x_{p})
\end{equation}\]</span></p></li>
</ul>
</div>
</div>
<div id="regression-splines" class="section level2">
<h2><span class="header-section-number">3.3</span> Regression Splines</h2>
<div id="overview" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Overview</h3>
<ul>
<li><p>Using <strong>regression splines</strong> is another common nonparametric approach for estimating a
mean function.</p></li>
<li><p>The most common type of spline used in the context of nonparametric regression is the <strong>cubic spline</strong>.</p></li>
<li><strong>Definition</strong>: A <strong>cubic spline</strong> with knots <span class="math inline">\(u_{1} &lt; u_{2} &lt; \ldots &lt; u_{q}\)</span> is a function <span class="math inline">\(f(x)\)</span> such that
<ul>
<li><span class="math inline">\(f(x)\)</span> is a cubic function over each of the intervals <span class="math inline">\((-\infty, u_{1}], [u_{1}, u_{2}], \ldots, [u_{q-1}, u_{q}], [u_{q}, \infty)\)</span>.</li>
<li><span class="math inline">\(f(x)\)</span>, <span class="math inline">\(f&#39;(x)\)</span>, and <span class="math inline">\(f&#39;&#39;(x)\)</span> are all continuous functions.</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>A commonly used set of <strong>basis functions</strong> for the set of cubic splines with knots <span class="math inline">\(u_{1} &lt; u_{2} &lt; \ldots &lt; u_{q}\)</span> is the <strong>B-spline</strong> basis functions.</p></li>
<li><p>This means that if <span class="math inline">\(\varphi_{1, B}(x), \ldots, \varphi_{q+4, B}(x)\)</span> are the B-spline <strong>basis functions</strong>
for the set of cubic splines with knots <span class="math inline">\(u_{1} &lt; u_{2} &lt; \ldots &lt; u_{q}\)</span>, we can represent any cubic spline
estimate of the mean function as
<span class="math display">\[\begin{equation}
\hat{\mu}(x) = \sum_{j=1}^{q+4} \hat{\beta}_{1}\varphi_{j, B}(x)
\end{equation}\]</span></p></li>
<li><p>The nice thing about using regression splines is that they can estimated
in the same way as you would in a typical regression setting.</p></li>
<li><p>The columns of the design matrix will be filled in with the values of <span class="math inline">\(\varphi_{j,B}(x_{i})\)</span>.</p></li>
</ul>
</div>
<div id="regression-splines-with-longitudinal-data-in-r" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Regression Splines with Longitudinal Data in R</h3>
<ul>
<li>Regression splines can be fitted in R by using the <code>splines</code> package</li>
</ul>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb134-1" data-line-number="1"><span class="kw">library</span>(splines)</a></code></pre></div>
<ul>
<li>The <code>bs</code> function in <code>splines</code> generates the B-spline “design” matrix</li>
</ul>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb135-1" data-line-number="1"><span class="kw">bs</span>(x, df, knots, degree)</a></code></pre></div>
<ul>
<li><code>x</code> - vector of covariates values. This can also just be the name of a variable when <code>bs</code> is used inside a function such as <code>geeglm</code>.</li>
<li><code>df</code> - the “degrees of freedom”. For a cubic spline this is actually <span class="math inline">\(q + 3\)</span> rather than <span class="math inline">\(q + 4\)</span>. If you just enter <code>df</code>, the <code>bs</code> function will pick the knots for you.</li>
<li><code>knots</code> - the vector of knots. If you don’t want to pick the knots, you can just enter a number for the <code>df</code>.</li>
<li><code>degree</code> - the degree of the piecewise polynomial. Typically, <code>degree=3</code> which would be a cubic spline.</li>
</ul>
<hr />
<ul>
<li><p>You can directly use <strong>regression splines</strong> within the <strong>“GEE framework”</strong>.</p></li>
<li><p>In this case, you can model the marginal mean (or part of the marginal mean function) with a spline.</p></li>
</ul>
<hr />
<ul>
<li><p>For example, with the <strong>bone data</strong>, suppose we want to fit separate curves for the male and female
groups.</p></li>
<li><p>We could express the mean function <span class="math inline">\(\mu(\cdot)\)</span> as
<span class="math display" id="eq:gee-bone">\[\begin{equation}
\mu(t_{ij}) = f_{0}(t_{ij}) + A_{ij}f_{1}(t_{ij})
\tag{3.2}
\end{equation}\]</span></p></li>
<li><p><span class="math inline">\(f_{0}(\cdot)\)</span> and <span class="math inline">\(f_{1}(\cdot)\)</span> would be modeled with regression splines.</p></li>
<li><p><span class="math inline">\(t_{ij}\)</span> is the value of <strong>age</strong> for observation (i,j)</p></li>
<li><p><span class="math inline">\(A_{ij} = 1\)</span> if the <span class="math inline">\((i,j)\)</span> observation corresponds to a male individual
and <span class="math inline">\(A_{ij} = 0\)</span> if the <span class="math inline">\((i,j)\)</span> observation corresponds to a female individual.</p></li>
</ul>
<hr />
<ul>
<li>To fit model <a href="nonpar-regression.html#eq:gee-bone">(3.2)</a> using the <code>geepack</code> package, you can use the following code</li>
</ul>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb136-1" data-line-number="1"><span class="kw">library</span>(splines)</a>
<a class="sourceLine" id="cb136-2" data-line-number="2">gee.bone &lt;-<span class="st"> </span><span class="kw">geeglm</span>(spnbmd <span class="op">~</span><span class="st"> </span><span class="kw">bs</span>(age, <span class="dt">df=</span><span class="dv">6</span>) <span class="op">+</span><span class="st"> </span>gender<span class="op">*</span><span class="kw">bs</span>(age,<span class="dt">df=</span><span class="dv">6</span>), <span class="dt">id=</span>idnum, <span class="dt">data=</span>bonedat)</a></code></pre></div>
<ul>
<li>We can plot the estimated mean functions by first extracting the <strong>fitted values</strong> for both the male and female groups:</li>
</ul>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb137-1" data-line-number="1">male.fitted &lt;-<span class="st"> </span>gee.bone<span class="op">$</span>fitted.values[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;male&quot;</span>]</a>
<a class="sourceLine" id="cb137-2" data-line-number="2">male.age &lt;-<span class="st"> </span>bonedat<span class="op">$</span>age[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;male&quot;</span>]</a>
<a class="sourceLine" id="cb137-3" data-line-number="3">female.fitted &lt;-<span class="st"> </span>gee.bone<span class="op">$</span>fitted.values[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;female&quot;</span>]</a>
<a class="sourceLine" id="cb137-4" data-line-number="4">female.age &lt;-<span class="st"> </span>bonedat<span class="op">$</span>age[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;female&quot;</span>]</a></code></pre></div>
<ul>
<li>Now, plot the fitted curves for both groups</li>
</ul>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb138-1" data-line-number="1"><span class="kw">plot</span>(bonedat<span class="op">$</span>age, bonedat<span class="op">$</span>spnbmd, <span class="dt">lwd=</span><span class="dv">1</span>, <span class="dt">xlab=</span><span class="st">&quot;age&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;spnbmd&quot;</span>, </a>
<a class="sourceLine" id="cb138-2" data-line-number="2">     <span class="dt">main=</span><span class="st">&quot;Regression Splines for the Bone Data&quot;</span>)</a>
<a class="sourceLine" id="cb138-3" data-line-number="3"><span class="kw">points</span>(bonedat<span class="op">$</span>age[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;male&quot;</span>], bonedat<span class="op">$</span>spnbmd[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;male&quot;</span>], </a>
<a class="sourceLine" id="cb138-4" data-line-number="4">       <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb138-5" data-line-number="5"><span class="kw">points</span>(bonedat<span class="op">$</span>age[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;female&quot;</span>], bonedat<span class="op">$</span>spnbmd[bonedat<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;female&quot;</span>], </a>
<a class="sourceLine" id="cb138-6" data-line-number="6">       <span class="dt">pch=</span><span class="dv">16</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)</a>
<a class="sourceLine" id="cb138-7" data-line-number="7"><span class="kw">lines</span>(male.age[<span class="kw">order</span>(male.age)], male.fitted[<span class="kw">order</span>(male.age)], <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb138-8" data-line-number="8"><span class="kw">lines</span>(female.age[<span class="kw">order</span>(female.age)], female.fitted[<span class="kw">order</span>(female.age)], <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, </a>
<a class="sourceLine" id="cb138-9" data-line-number="9">      <span class="dt">lwd=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb138-10" data-line-number="10"><span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>), <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>), <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">bty=</span><span class="st">&#39;n&#39;</span>)</a></code></pre></div>
<p><img src="03-NonParRegression_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<hr />

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-rice1991">
<p>Rice, John A, and Bernard W Silverman. 1991. “Estimating the Mean and Covariance Structure Nonparametrically When the Data Are Curves.” <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 53 (1): 233–43.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="missing-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="glmm-lasso.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
